List of different **techniques** and **architectural patterns** commonly used with **LLMs (Large Language Models)** to enhance, optimize, or specialize their capabilities in real-world applications:

---

### ğŸ”Œ **Client/Serving Techniques**
These are methods to interact with LLMs via APIs or client setups:

1. **MCP Client (Multi-Chain Prompting)** â€“ A way to manage and combine multiple prompts in a chain for more complex reasoning or tasks.
2. **LangChain** â€“ A framework to chain prompts, memory, agents, and tools together around LLMs.
3. **LLM Client SDKs (e.g., OpenAI SDK, HuggingFace Transformers)** â€“ Native clients to call LLM APIs easily.
4. **LLM-as-a-Service (e.g., DeepSeek, Claude, GPT-4 API)** â€“ Access to hosted LLMs via API endpoints.
5. **WebLLM / Local LLM Clients** â€“ Running LLMs on the edge (browser or local machine).

---

### ğŸ“š **Data Augmentation Techniques**
Used to enhance the LLMâ€™s knowledge or relevance:

6. **RAG (Retrieval-Augmented Generation)** â€“ Combines LLM with external search/knowledge base to fetch relevant data before generation.
7. **FiD (Fusion-in-Decoder)** â€“ Similar to RAG but fuses retrieved documents directly in the decoding phase.
8. **Memory-Augmented Models** â€“ Incorporates short-term or long-term memory to retain context.
9. **Prompt Tuning / Soft Prompting** â€“ Optimizing prompts using learnable vectors instead of plain text.

---

### ğŸ§  **Fine-Tuning & Training Techniques**
Used to adapt or specialize LLMs:

10. **Fine-Tuning (Full or Partial)** â€“ Training the model on domain-specific data.
11. **LoRA (Low-Rank Adaptation)** â€“ Efficient fine-tuning using low-rank matrices to reduce training cost.
12. **PEFT (Parameter-Efficient Fine-Tuning)** â€“ Family of methods like LoRA, adapters, prefix-tuning.
13. **Instruction Tuning** â€“ Fine-tuning LLMs on instruction-following tasks (e.g., FLAN, Alpaca).
14. **RLHF (Reinforcement Learning with Human Feedback)** â€“ Fine-tuning models based on human preference data.

---

### ğŸ•¸ï¸ **Architecture & Design Patterns**
For LLM-based systems:

15. **Agentic Workflows** â€“ Use agents (LLM-based) to plan and execute tasks autonomously using tools (e.g., AutoGPT, LangGraph).
16. **Function Calling / Tool Use** â€“ LLM calls external APIs/tools to augment capabilities.
17. **Multi-Agent Systems** â€“ Several LLM agents collaborating or competing on tasks.
18. **Tree of Thought (ToT)** â€“ Branching reasoning paths for more robust decision-making.
19. **Graph of Thought (GoT)** â€“ Advanced version of ToT where reasoning paths form a graph.

---

### ğŸ§¾ **Prompt Engineering Techniques**
To control or guide LLM output:

20. **Zero-shot / Few-shot Prompting**
21. **Chain-of-Thought Prompting (CoT)** â€“ Encourages the model to reason step by step.
22. **Self-Consistency** â€“ Run multiple CoT paths and pick the most frequent answer.
23. **ReAct (Reason + Act)** â€“ Encourages the LLM to reason before using external tools.
24. **Meta-Prompting** â€“ Prompts that generate new prompts or strategies.

---

### ğŸ“¦ **LLM Application Infrastructure**
To improve performance or UX:

25. **Caching (e.g., Redis for prompt-response caching)**
26. **Streaming Responses** â€“ For real-time token-by-token output.
27. **Rate Limiting and Monitoring** â€“ To handle traffic and errors effectively.
28. **Embeddings and Vector Stores (e.g., FAISS, Pinecone)** â€“ For semantic search and similarity.
29. **Context Compression / Summarization** â€“ Reducing previous context into summaries.

---
